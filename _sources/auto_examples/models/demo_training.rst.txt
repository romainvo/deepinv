
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/models/demo_training.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        New to DeepInverse? Get started with the basics with the
        :ref:`5 minute quickstart tutorial <sphx_glr_auto_examples_basics_demo_quickstart.py>`.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_models_demo_training.py:


Training a reconstruction model
====================================================================================================

This example provides a very simple quick start introduction to training reconstruction networks with
DeepInverse for solving imaging inverse problems.

Training requires these components, all of which you can define with DeepInverse:

* A `model` to be trained from :ref:`reconstructors <reconstructors>` or define your own.
* A `physics` from our :ref:`list of physics <physics>`. Or, :ref:`bring your own physics <sphx_glr_auto_examples_basics_demo_custom_dataset.py>`.
* A `dataset` of images and/or measurements from :ref:`datasets <datasets>`. Or, :ref:`bring your own dataset <sphx_glr_auto_examples_basics_demo_custom_dataset.py>`.
* A `loss` from our :ref:`loss functions <loss>`.
* A `metric` from our :ref:`metrics <metric>`.

Here, we demonstrate a simple experiment of training a UNet
on an inpainting task on the Urban100 dataset of natural images.

.. GENERATED FROM PYTHON SOURCE LINES 20-27

.. code-block:: Python


    import deepinv as dinv
    import torch

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"
    rng = torch.Generator(device=device).manual_seed(0)








.. GENERATED FROM PYTHON SOURCE LINES 28-33

Setup
-----

First, define the physics that we want to train on.


.. GENERATED FROM PYTHON SOURCE LINES 33-36

.. code-block:: Python


    physics = dinv.physics.Inpainting((1, 64, 64), mask=0.8, device=device, rng=rng)








.. GENERATED FROM PYTHON SOURCE LINES 37-43

Then define the dataset. Here we simulate a dataset of measurements from Urban100.

.. tip::
    See :ref:`datasets <datasets>` for types of datasets DeepInverse supports: e.g. paired, ground-truth-free,
    single-image...


.. GENERATED FROM PYTHON SOURCE LINES 43-72

.. code-block:: Python


    from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, Grayscale

    dataset = dinv.datasets.Urban100HR(
        ".",
        download=True,
        transform=Compose([ToTensor(), Grayscale(), Resize(256), CenterCrop(64)]),
    )

    train_dataset, test_dataset = torch.utils.data.random_split(
        torch.utils.data.Subset(dataset, range(50)), (0.8, 0.2)
    )

    dataset_path = dinv.datasets.generate_dataset(
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        physics=physics,
        device=device,
        save_dir=".",
        batch_size=1,
    )

    train_dataloader = torch.utils.data.DataLoader(
        dinv.datasets.HDF5Dataset(dataset_path, train=True), shuffle=True
    )
    test_dataloader = torch.utils.data.DataLoader(
        dinv.datasets.HDF5Dataset(dataset_path, train=False), shuffle=False
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/135388067 [00:00<?, ?it/s]      0%|          | 128k/129M [00:00<02:07, 1.06MB/s]      0%|          | 448k/129M [00:00<01:00, 2.23MB/s]      1%|▏         | 1.62M/129M [00:00<00:20, 6.57MB/s]      4%|▍         | 5.69M/129M [00:00<00:06, 20.2MB/s]     10%|█         | 13.1M/129M [00:00<00:03, 40.5MB/s]     16%|█▌        | 20.6M/129M [00:00<00:02, 53.1MB/s]     21%|██▏       | 27.5M/129M [00:00<00:01, 59.1MB/s]     27%|██▋       | 34.9M/129M [00:00<00:01, 64.9MB/s]     33%|███▎      | 42.3M/129M [00:00<00:01, 68.6MB/s]     39%|███▊      | 49.8M/129M [00:01<00:01, 71.3MB/s]     44%|████▍     | 57.1M/129M [00:01<00:01, 73.0MB/s]     50%|████▉     | 64.5M/129M [00:01<00:00, 74.1MB/s]     56%|█████▌    | 71.7M/129M [00:01<00:00, 74.4MB/s]     61%|██████▏   | 79.2M/129M [00:01<00:00, 75.4MB/s]     67%|██████▋   | 86.8M/129M [00:01<00:00, 76.5MB/s]     73%|███████▎  | 94.1M/129M [00:01<00:00, 76.5MB/s]     79%|███████▊  | 102M/129M [00:01<00:00, 76.8MB/s]      84%|████████▍ | 109M/129M [00:01<00:00, 76.3MB/s]     90%|█████████ | 116M/129M [00:01<00:00, 76.6MB/s]     96%|█████████▌| 124M/129M [00:02<00:00, 77.0MB/s]    100%|██████████| 129M/129M [00:02<00:00, 64.0MB/s]
    Extracting:   0%|          | 0/101 [00:00<?, ?it/s]    Extracting:  21%|██        | 21/101 [00:00<00:00, 203.94it/s]    Extracting:  48%|████▊     | 48/101 [00:00<00:00, 240.01it/s]    Extracting:  72%|███████▏  | 73/101 [00:00<00:00, 223.97it/s]    Extracting:  95%|█████████▌| 96/101 [00:00<00:00, 219.81it/s]    Extracting: 100%|██████████| 101/101 [00:00<00:00, 222.96it/s]
    Dataset has been successfully downloaded.
    Dataset has been saved at ./dinv_dataset0.h5




.. GENERATED FROM PYTHON SOURCE LINES 73-75

Visualize a data sample:


.. GENERATED FROM PYTHON SOURCE LINES 75-80

.. code-block:: Python


    x, y = next(iter(test_dataloader))
    dinv.utils.plot({"Ground truth": x, "Measurement": y, "Mask": physics.mask})





.. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_001.png
   :alt: Ground truth, Measurement, Mask
   :srcset: /auto_examples/models/images/sphx_glr_demo_training_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 81-88

For the model we use an artifact removal model, where
:math:`\phi_{\theta}` is a U-Net

.. math::

    f_{\theta}(y) = \phi_{\theta}(A^{\top}(y))


.. GENERATED FROM PYTHON SOURCE LINES 88-93

.. code-block:: Python


    model = dinv.models.ArtifactRemoval(
        dinv.models.UNet(1, 1, scales=2, batch_norm=False).to(device)
    )








.. GENERATED FROM PYTHON SOURCE LINES 94-110

Train the model
----------------------------------------------------------------------------------------
We train the model using the :class:`deepinv.Trainer` class,
which cleanly handles all steps for training.

We perform supervised learning and use the mean squared error as loss function.
See :ref:`losses <loss>` for all supported state-of-the-art loss functions.

We evaluate using the PSNR metric.
See :ref:`metrics <metric>` for all supported metrics.

.. note::

      In this example, we only train for a few epochs to keep the training time short.
      For a good reconstruction quality, we recommend to train for at least 100 epochs.


.. GENERATED FROM PYTHON SOURCE LINES 110-129

.. code-block:: Python



    trainer = dinv.Trainer(
        model=model,
        physics=physics,
        optimizer=torch.optim.Adam(model.parameters(), lr=1e-3),
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=5,
        losses=dinv.loss.SupLoss(metric=dinv.metric.MSE()),
        metrics=dinv.metric.PSNR(),
        device=device,
        plot_images=True,
        show_progress_bar=False,
    )

    _ = trainer.train()





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_002.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_003.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_003.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_004.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_005.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_005.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_006.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_007.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_007.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_008.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_008.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_009.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_009.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_010.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_010.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_011.png
         :alt: Ground truth, Measurement, Reconstruction
         :srcset: /auto_examples/models/images/sphx_glr_demo_training_011.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 443585 trainable parameters
    Train epoch 0: TotalLoss=0.017, PSNR=19.737
    Eval epoch 0: PSNR=24.153
    Best model saved at epoch 1
    Train epoch 1: TotalLoss=0.003, PSNR=26.059
    Eval epoch 1: PSNR=27.708
    Best model saved at epoch 2
    Train epoch 2: TotalLoss=0.002, PSNR=28.6
    Eval epoch 2: PSNR=29.931
    Best model saved at epoch 3
    Train epoch 3: TotalLoss=0.001, PSNR=29.363
    Eval epoch 3: PSNR=30.338
    Best model saved at epoch 4
    Train epoch 4: TotalLoss=0.001, PSNR=30.312
    Eval epoch 4: PSNR=31.0
    Best model saved at epoch 5




.. GENERATED FROM PYTHON SOURCE LINES 130-135

Test the network
--------------------------------------------
We can now test the trained network using the :func:`deepinv.test` function.

The testing function will compute metrics and plot and save the results.

.. GENERATED FROM PYTHON SOURCE LINES 135-137

.. code-block:: Python


    trainer.test(test_dataloader)



.. image-sg:: /auto_examples/models/images/sphx_glr_demo_training_012.png
   :alt: Ground truth, Measurement, No learning, Reconstruction
   :srcset: /auto_examples/models/images/sphx_glr_demo_training_012.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=31.0, PSNR no learning=14.377
    Test results:
    PSNR no learning: 14.377 +- 2.244
    PSNR: 31.000 +- 3.071

    {'PSNR no learning': np.float64(14.376654052734375), 'PSNR no learning_std': np.float64(2.24376346747964), 'PSNR': np.float64(31.000277709960937), 'PSNR_std': np.float64(3.0713311241299124)}




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 19.523 seconds)


.. _sphx_glr_download_auto_examples_models_demo_training.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_training.ipynb <demo_training.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_training.py <demo_training.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_training.zip <demo_training.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
